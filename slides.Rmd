---
title: "Confusion"
author: "Lyron Winderbaum"
date: "`r Sys.Date()`"
output: ioslides_presentation
---

## Contents

- Statistical Tests.
- Confusion Matrix.
- Family-wise Error Rate.
- R Markdown.

## Statistical Tests

What is a statistical test?

In this context, a test is a method for answering a 
binary question --- a question with two possible outcomes.

We will use the terminology Positive/ Negative for these two outcomes although 
different terminology might be appropriate in any given context.

<!-- Some examples: -->

<!-- - A test for HIV can result in positive/ negative results. -->
<!-- - Similarly a test for LNM. -->
<!-- - Testing for the difference in the mean serum concentration of a protein  -->
<!--   between two experimental groups results in either a difference being detected,  -->
<!--   or no difference detected. -->

## Confusion Matrix

-------------------- -------------------- 
 TP: True  Positive   FN: False Negative
 FP: False Positive   TN: True  Negative 
-------------------- -------------------- 

This 2x2 table is (confusingly) called the confusion matrix.

The words "True" and "False" refer to the truth, while the words "Positive"
and "Negative" refer to the outcome of your test.

## Confusion Matrix
Many common concepts are directly derived from the confusion matrix.
Including many TLA (Three Letter Acronyms) that you should recognise and/ or be 
able to infer.

- Significance: FPR = FP / (FP + TN) = 1 - specificity
- Power: TPR = TP / (TP + FN) = sensitivity
- Specificity: TNR = TN / (FP + TN))
- Prevalence: (TP + FN) / (TP + FN + FP + TN)
- Precision: PPV = TP / (TP + FP)
- False Discovery Rate: FDR = FP / (TP + FP) = 1 - PPV

Notice ROC curves are constructed by plotting Significance and Power against 
each other.

## Confusion Matrix
And some that you might not recognise.

- Accuracy: (TP + TN) / (TP + FN + FP + TN)
- F1 = 2TP / (2TP + FP + FN)
- Informedness: sensitivity + specificity - 1 = DIPPS

and in case you're curious and interested in further reading,
you might also like to check out the 
[Mathews Correlation Coefficient](https://en.wikipedia.org/wiki/Matthews_correlation_coefficient) (MCC). 

If you do follow up by reading more about this topic, note
that my notation here is consistent with that of the 
[wikipedia page](https://en.wikipedia.org/wiki/Sensitivity_and_specificity).

## P-Values
But for now lets just focus on one thing: Significance, also known as False 
Positive Rate (FPR), or type I error rate.

Well, assuming that you have calculated your p-values correctly, and 
that any required assumptions are true, then making our decision in this way 
will produce a FPR of 0.05.

Ok so what's the catch?


## Family-wise Error Rate

The catch is when you are performing several tests simultaneously.

Although the FPR within each individual test should be 0.05, the probability of
there being at least one false positive amongst the set of tests performed will
typlically be much greater than 5%. This is called the Family-wise error rate
(FWER).

Often attention will be focused on differences found, which will naturally bias
results towards including these False Positives, hence increasing the likelihood 
of reporting false results.

## Multiple Testing Correction
It can however be addressed by adjusting the p-value cutoff used in the 
decision-making process, thereby controlling the FWER. 

In practice, this results in using more stringent p-value cutoffs in order to 
guarantee a 5% FWER. 

## R Markdown

This is an R Markdown presentation. Markdown is a simple formatting syntax for
authoring HTML, PDF, and MS Word documents. For more details on using R Markdown
see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes
both content as well as the output of any embedded R code chunks within the
document. A couple of examples follow.

## Slide with R Output

```{r cars, echo = TRUE}
summary(cars)
```

## Slide with Plot

```{r pressure}
plot(pressure)
```
